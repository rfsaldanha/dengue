{
  "hash": "f6e3febd21bd45e8deab64d3abc89641",
  "result": {
    "markdown": "---\ntitle: \"Global and subset models\"\nauthor: \"Raphael Saldanha\"\ndate: last-modified\n---\n\n\nThis notebooks aims to reproduce the metodology of the paper submitted to the SBD2023 conference, implementing the global and subset modelling.\n\nThis methodology aims to compare the perfomance of models trained with data from all municipalities time-series (*global models*) and models trained with subset of munipalities time-series (*subset models*).\n\nThose subset will be created by a clustering algorithm considering the municipalities cases time-series.\n\n## Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(tidymodels)\nlibrary(bonsai)\nlibrary(finetune)\nlibrary(modeltime)\nlibrary(timetk)\nlibrary(dtwclust)\nlibrary(kableExtra)\nlibrary(tictoc)\n```\n:::\n\n\n## Load data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntdengue <- read_parquet(file = \"tdengue.parquet\") %>%\n  drop_na() %>%\n  select(mun, date, starts_with(\"cases\"))\n```\n:::\n\n\n::: callout-note\n-   NA values are created when the lagged variables were calculated. The rows containing those NA values are dropped due machine learning regressors constraints.\n\n-   For validation purposes, only the `cases` and `cases_lag*` covariates variables are keep.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(tdengue)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 161,370\nColumns: 9\n$ mun        <chr> \"110002\", \"110002\", \"110002\", \"110002\", \"110002\", \"110002\",…\n$ date       <date> 2011-02-06, 2011-02-13, 2011-02-20, 2011-02-27, 2011-03-06…\n$ cases      <dbl> -0.51044592, 0.07880156, 0.66804904, 0.07880156, -0.5104459…\n$ cases_lag1 <dbl> 2.43579149, -0.51044592, 0.07880156, 0.66804904, 0.07880156…\n$ cases_lag2 <dbl> 0.66804904, 2.43579149, -0.51044592, 0.07880156, 0.66804904…\n$ cases_lag3 <dbl> 0.07880156, 0.66804904, 2.43579149, -0.51044592, 0.07880156…\n$ cases_lag4 <dbl> 0.66804904, 0.07880156, 0.66804904, 2.43579149, -0.51044592…\n$ cases_lag5 <dbl> 0.66804904, 0.66804904, 0.07880156, 0.66804904, 2.43579149,…\n$ cases_lag6 <dbl> -0.51044592, 0.66804904, 0.66804904, 0.07880156, 0.66804904…\n```\n:::\n:::\n\n\n## Clustering\n\nThis procedure goal is to cluster the municipalities considering the cases time series similarities between them.\n\n### Prepare data\n\nPrepare the data for use with the `dtwclust` package, pivoting the panel data to a wide format and matrix object.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncdengue <- tdengue %>%\n  select(mun, date, cases) %>%\n  mutate(mun = paste0(\"m_\", mun)) %>%\n  arrange(mun, date) %>%\n  pivot_wider(names_from = mun, values_from = cases) %>%\n  select(-date) %>%\n  t() %>%\n  tslist()\n```\n:::\n\n\n### SBD method\n\nThe SBD method is used to cluster the municipalities, considering a shape-bases distance (k-Shape clustering algorithm). More details on the [publicated methodology](https://doi.org/10.1145/2723372.2737793).\n\n`r``length(unique(tdengue$mun))` municipalities will be clustered.\n\nThe clustering algorithm is applied with a varying number of $k$ partitions from 3 to 8.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nk_seq <- 3:8\n\ntic()\nclust <- tsclust(\n  series = cdengue, \n  type = \"partitional\", \n  k = k_seq,\n  distance = \"sbd\",\n  seed = 123\n)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.245 sec elapsed\n```\n:::\n:::\n\n\n### Cluster Validity Indices (CVI)\n\nTo choose the number of partitions, the Silhouette statistic is observed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(clust) <- paste0(\"k_\", k_seq)\nres_cvi <- sapply(clust, cvi, type = \"internal\") %>% \n  t() %>%\n  as_tibble(rownames = \"k\") %>%\n  arrange(-Sil)\n\nres_cvi %>%\n  kbl() %>%\n  kable_styling()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> k </th>\n   <th style=\"text-align:right;\"> Sil </th>\n   <th style=\"text-align:right;\"> SF </th>\n   <th style=\"text-align:right;\"> CH </th>\n   <th style=\"text-align:right;\"> DB </th>\n   <th style=\"text-align:right;\"> DBstar </th>\n   <th style=\"text-align:right;\"> D </th>\n   <th style=\"text-align:right;\"> COP </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> k_3 </td>\n   <td style=\"text-align:right;\"> 0.1747336 </td>\n   <td style=\"text-align:right;\"> 0.3501838 </td>\n   <td style=\"text-align:right;\"> 36.98758 </td>\n   <td style=\"text-align:right;\"> 2.260992 </td>\n   <td style=\"text-align:right;\"> 2.400068 </td>\n   <td style=\"text-align:right;\"> 0.0805315 </td>\n   <td style=\"text-align:right;\"> 0.3705055 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> k_4 </td>\n   <td style=\"text-align:right;\"> 0.1669509 </td>\n   <td style=\"text-align:right;\"> 0.2526978 </td>\n   <td style=\"text-align:right;\"> 34.15648 </td>\n   <td style=\"text-align:right;\"> 4.050796 </td>\n   <td style=\"text-align:right;\"> 4.597881 </td>\n   <td style=\"text-align:right;\"> 0.0676247 </td>\n   <td style=\"text-align:right;\"> 0.3688632 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> k_7 </td>\n   <td style=\"text-align:right;\"> 0.1625835 </td>\n   <td style=\"text-align:right;\"> 0.1135484 </td>\n   <td style=\"text-align:right;\"> 20.46483 </td>\n   <td style=\"text-align:right;\"> 2.802248 </td>\n   <td style=\"text-align:right;\"> 3.289527 </td>\n   <td style=\"text-align:right;\"> 0.0805315 </td>\n   <td style=\"text-align:right;\"> 0.3497498 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> k_8 </td>\n   <td style=\"text-align:right;\"> 0.1294623 </td>\n   <td style=\"text-align:right;\"> 0.1012342 </td>\n   <td style=\"text-align:right;\"> 20.25096 </td>\n   <td style=\"text-align:right;\"> 1.906407 </td>\n   <td style=\"text-align:right;\"> 2.268955 </td>\n   <td style=\"text-align:right;\"> 0.0660755 </td>\n   <td style=\"text-align:right;\"> 0.3456895 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> k_6 </td>\n   <td style=\"text-align:right;\"> 0.0914225 </td>\n   <td style=\"text-align:right;\"> 0.1541329 </td>\n   <td style=\"text-align:right;\"> 29.42529 </td>\n   <td style=\"text-align:right;\"> 4.230747 </td>\n   <td style=\"text-align:right;\"> 7.206356 </td>\n   <td style=\"text-align:right;\"> 0.0280277 </td>\n   <td style=\"text-align:right;\"> 0.3317256 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> k_5 </td>\n   <td style=\"text-align:right;\"> 0.0517861 </td>\n   <td style=\"text-align:right;\"> 0.1915811 </td>\n   <td style=\"text-align:right;\"> 27.11958 </td>\n   <td style=\"text-align:right;\"> 3.855824 </td>\n   <td style=\"text-align:right;\"> 5.374118 </td>\n   <td style=\"text-align:right;\"> 0.0353306 </td>\n   <td style=\"text-align:right;\"> 0.3523987 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Select cluster with higher Silhouette statistic\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsel_clust <- clust[[res_cvi[[1,1]]]]\n\nplot(sel_clust)\n```\n\n::: {.cell-output-display}\n![](dengue_ts_global_subset_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n### Cluster sizes\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(sel_clust@cluster)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  1   2   3 \n 34 251  41 \n```\n:::\n:::\n\n\n### Identify municipalities and cluster id\n\nFinally, the cluster partition ID is added to the main dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_ids <- tibble(\n  mun = names(cdengue) %>% substr(3, 9),\n  group = as.character(sel_clust@cluster)\n) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntdengue <- left_join(tdengue, cluster_ids, by = \"mun\")\n```\n:::\n\n\n## Train and test split\n\nSplit the data into training and testing. The function `time_series_split` handles the time series, not shuffling them, and considering the panel data format, as depicted in the message about overlapping timestamps detected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntdengue_split <- tdengue %>%\n  time_series_split(\n    date_var = date, \n    assess = 52*2,\n    cumulative = TRUE\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nData is not ordered by the 'date_var'. Resamples will be arranged by `date`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nOverlapping Timestamps Detected. Processing overlapping time series together using sliding windows.\n```\n:::\n\n```{.r .cell-code}\ntdengue_split\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Analysis/Assess/Total>\n<127466/33904/161370>\n```\n:::\n:::\n\n\n## K-folds\n\nThe training set will be split into k folds.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntdengue_split_folds <- training(tdengue_split) %>%\n  vfold_cv(v = 5)\n```\n:::\n\n\n## Recipes\n\nThe global and subset models training specification are called recipes. The procedure bellow creates a list of those recipes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipes_list <- list()\n```\n:::\n\n\n### Global\n\nThe global training recipe uses data from all municipalities for training the models.\n\n-   The date and group variables are removed prior training\n\n-   The municipality identification variable is treated as an Id variable, taking no place as a predictor in the training process\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_global <- recipe(cases ~ ., data = training(tdengue_split)) %>%\n  step_rm(date, group) %>%\n  update_role(mun, new_role = \"id variable\")\n\nrecipes_list <- append(recipes_list, list(global = recipe_global))\n\nrm(recipe_global)\n```\n:::\n\n\n### Groups\n\n-   For each group created by the clustering process, a specific training recipe will be created. For this, the first step is to filter rows from the training set, keep only the rows belonging to the group in the loop\n\n-   The date and group variables are removed prior training\n\n-   The municipality identification variable is treated as an Id variable, taking no place as a predictor in the training process\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor(g in unique(tdengue$group)){\n  tmp <- recipe(cases ~ ., data = training(tdengue_split)) %>%\n    step_filter(group == !!g) %>%\n    step_rm(date, group) %>%\n    update_role(mun, new_role = \"id variable\")\n  \n  tmp <- list(tmp)\n  tmp <- setNames(tmp, paste0(\"g\", g))\n  \n  recipes_list <- append(recipes_list, tmp)\n  \n  rm(tmp)\n}\n```\n:::\n\n\n## Regressors specification\n\n### Random forest\n\nA Random Forest spefication using the `ranger` engine. The `trees` and `min_n` hyperparameters will be tuned.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_spec <- rand_forest(\n  trees = tune(),\n  min_n = tune()\n) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"regression\")\n```\n:::\n\n\n### LightGBM\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lgbm_spec <- boost_tree() %>%\n#   set_engine(\"lightgbm\") %>%\n#   set_mode(\"regression\")\n```\n:::\n\n\n## Workflow set\n\nThis step creates a workflow set, combining the training recipes and regressors specifications.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_workflows <- workflow_set(\n  preproc = recipes_list, \n  models = list(rf = rf_spec), \n  cross = TRUE\n)\n```\n:::\n\n\n## Tune\n\nThis step tunes the training hyperparameters of each workflow.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoParallel::registerDoParallel()\n\ntic()\nrace_results <- \n  all_workflows %>%\n  workflow_map(\n    \"tune_race_anova\",\n    seed = 345,\n    resamples = tdengue_split_folds,\n    grid = 10,\n    control = control_race(parallel_over = \"everything\"),\n    verbose = TRUE\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni 1 of 4 tuning:     global_rf\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in mclapply(argsList, FUN, mc.preschedule = preschedule, mc.set.seed =\nset.seed, : scheduled core 5 did not deliver a result, all values of the job\nwill be affected\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ 1 of 4 tuning:     global_rf (23m 20.7s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\ni 2 of 4 tuning:     g3_rf\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ 2 of 4 tuning:     g3_rf (2m 17.7s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\ni 3 of 4 tuning:     g1_rf\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ 3 of 4 tuning:     g1_rf (1m 18s)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\ni 4 of 4 tuning:     g2_rf\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ 4 of 4 tuning:     g2_rf (18m 1.7s)\n```\n:::\n\n```{.r .cell-code}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2698.898 sec elapsed\n```\n:::\n:::\n\n\n## Fit\n\nEach workflow will be trained using the tuned hyperparameters, considering the RMSE metric as reference.\n\nThis procedure creates a list of trained models, containing the fit results and a list of the municipalities used on the training of each workflow.\n\nThe global workflow is trained with data from all municipalities and the subsets workflows are trained using the respective municipalities list given by the cluster algorithm.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrained_models <- list()\nfor(w in unique(race_results$wflow_id)){\n  best_tune <- race_results %>%\n    extract_workflow_set_result(w) %>%\n    select_best(\"rmse\")\n  \n  final_fit <- race_results %>%\n    extract_workflow(w) %>%\n    finalize_workflow(best_tune) %>%\n    fit(training(tdengue_split))\n  \n  mold <- extract_mold(final_fit)\n  train_ids <- mold$extras$roles$`id variable` %>%\n    distinct() %>%\n    pull() %>%\n    as.character()\n  \n  final_fit <- list(\n    list(\n      \"final_fit\" = final_fit, \n      \"train_ids\" = train_ids\n    )\n  )\n  \n  final_fit <- setNames(final_fit, paste0(w))\n  \n  trained_models <- append(trained_models, final_fit)\n}\n```\n:::\n\n\n## Accuracy\n\nAfter training each workflow, the accuracy of the models are obtained applying the fitted models on the testing set.\n\nFor the global model, all municipalities are using for testing. For the subsets models, only data from the subset's municipalities are considered for testing.\n\nThe RMSE metric is obtained for each workflow and municipality.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels_accuracy <- tibble()\nfor(t in 1:length(trained_models)){\n  \n  model_tbl <- modeltime_table(trained_models[[t]][[1]]) \n  testing_set <- testing(tdengue_split) %>%\n    filter(mun %in% trained_models[[t]][[2]])\n  \n\n  calib_tbl <- model_tbl %>%\n      modeltime_calibrate(\n        new_data = testing_set, \n        id       = \"mun\"\n      )\n  \n  res <- calib_tbl %>% \n      modeltime_accuracy(\n        acc_by_id = TRUE, \n        metric_set = metric_set(rmse)\n      )\n  \n  res$.model_id <- word(names(trained_models[t]), 1, sep = \"_\")\n  \n  models_accuracy <- bind_rows(models_accuracy, res)\n}\n```\n:::\n\n\nThis plot presents the RMSE distribution across the workflows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = models_accuracy, aes(x = .model_id, y = rmse, fill = .model_desc)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](dengue_ts_global_subset_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n## Session info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.1.2 (2021-11-01)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.2 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nRandom number generation:\n RNG:     L'Ecuyer-CMRG \n Normal:  Inversion \n Sample:  Rejection \n \nlocale:\n [1] LC_CTYPE=pt_BR.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] rlang_1.1.1        ranger_0.15.1      tictoc_1.2         kableExtra_1.3.4  \n [5] dtwclust_5.5.12    dtw_1.23-1         proxy_0.4-27       timetk_2.8.3      \n [9] modeltime_1.2.7    finetune_1.1.0     bonsai_0.2.1       yardstick_1.2.0   \n[13] workflowsets_1.0.1 workflows_1.1.3    tune_1.1.1         rsample_1.1.1     \n[17] recipes_1.0.6      parsnip_1.1.0      modeldata_1.1.0    infer_1.0.4       \n[21] dials_1.2.0        scales_1.2.1       broom_1.0.5        tidymodels_1.1.0  \n[25] arrow_12.0.1       lubridate_1.9.2    forcats_1.0.0      stringr_1.5.0     \n[29] dplyr_1.1.2        purrr_1.0.1        readr_2.1.4        tidyr_1.3.0       \n[33] tibble_3.2.1       ggplot2_3.4.2      tidyverse_2.0.0   \n\nloaded via a namespace (and not attached):\n  [1] backports_1.4.1     systemfonts_1.0.4   plyr_1.8.8         \n  [4] splines_4.1.2       listenv_0.9.0       digest_0.6.32      \n  [7] foreach_1.5.2       htmltools_0.5.5     fansi_1.0.4        \n [10] magrittr_2.0.3      cluster_2.1.2       doParallel_1.0.17  \n [13] tzdb_0.4.0          globals_0.16.2      gower_1.0.1        \n [16] RcppParallel_5.1.7  xts_0.13.1          svglite_2.1.1      \n [19] hardhat_1.3.0       timechange_0.2.0    prettyunits_1.1.1  \n [22] colorspace_2.1-0    rvest_1.0.3         ggrepel_0.9.3      \n [25] xfun_0.39           jsonlite_1.8.7      lme4_1.1-34        \n [28] survival_3.2-13     zoo_1.8-12          iterators_1.0.14   \n [31] glue_1.6.2          gtable_0.3.3        ipred_0.9-14       \n [34] webshot_0.5.5       future.apply_1.11.0 Rcpp_1.0.10        \n [37] viridisLite_0.4.2   xtable_1.8-4        clue_0.3-64        \n [40] GPfit_1.0-8         bit_4.0.5           stats4_4.1.2       \n [43] lava_1.7.2.1        StanHeaders_2.26.27 prodlim_2023.03.31 \n [46] htmlwidgets_1.6.2   httr_1.4.6          modeltools_0.2-23  \n [49] ellipsis_0.3.2      pkgconfig_2.0.3     farver_2.1.1       \n [52] nnet_7.3-17         utf8_1.2.3          tidyselect_1.2.0   \n [55] labeling_0.4.2      DiceDesign_1.9      reshape2_1.4.4     \n [58] later_1.3.1         munsell_0.5.0       tools_4.1.2        \n [61] cli_3.6.1           generics_0.1.3      evaluate_0.21      \n [64] fastmap_1.1.1       yaml_2.3.7          knitr_1.43         \n [67] bit64_4.0.5         nlme_3.1-155        future_1.33.0      \n [70] mime_0.12           xml2_1.3.4          flexclust_1.4-1    \n [73] compiler_4.1.2      rstudioapi_0.14     lhs_1.1.6          \n [76] stringi_1.7.12      highr_0.10          RSpectra_0.16-1    \n [79] lattice_0.20-45     Matrix_1.5-4.1      nloptr_2.0.3       \n [82] shinyjs_2.1.0       vctrs_0.6.3         pillar_1.9.0       \n [85] lifecycle_1.0.3     furrr_0.3.1         data.table_1.14.8  \n [88] httpuv_1.6.11       R6_2.5.1            promises_1.2.0.1   \n [91] parallelly_1.36.0   codetools_0.2-18    boot_1.3-28        \n [94] MASS_7.3-55         assertthat_0.2.1    withr_2.5.0        \n [97] parallel_4.1.2      hms_1.1.3           grid_4.1.2         \n[100] rpart_4.1.16        timeDate_4022.108   minqa_1.2.5        \n[103] class_7.3-20        rmarkdown_2.23      shiny_1.7.4        \n```\n:::\n:::\n\n\n## References\n\n-   <https://business-science.github.io/modeltime/articles/modeling-panel-data.html>\n\n-   <https://blog.bguarisma.com/series/time-series-forecasting>\n",
    "supporting": [
      "dengue_ts_global_subset_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}