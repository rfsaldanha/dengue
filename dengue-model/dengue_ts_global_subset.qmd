---
title: "Global and subset models"
author: "Raphael Saldanha"
date: last-modified
---

This notebooks aims to reproduce the metodology of the paper submitted to the SBD2023 conference, implementing the global and subset modelling.

This methodology aims to compare the perfomance of models trained with data from all municipalities time-series (*global models*) and models trained with subset of munipalities time-series (*subset models*).

Those subset will be created by a clustering algorithm considering the municipalities cases time-series.

## Packages

```{r}
#| message: false
library(tidyverse)
library(arrow)
library(tidymodels)
library(bonsai)
library(finetune)
library(modeltime)
library(timetk)
library(dtwclust)
library(kableExtra)
library(tictoc)
```

## Load data

```{r}
tdengue <- read_parquet(file = "tdengue.parquet") %>%
  drop_na() %>%
  select(mun, date, starts_with("cases"))
```

::: callout-note
-   NA values are created when the lagged variables were calculated. The rows containing those NA values are dropped.

-   For validation purposes, only the `cases` and `cases_lag*` covariates variables are keep.
:::

```{r}
glimpse(tdengue)
```

## Clustering

This procedure goal is to cluster the municipalities considering the cases time-series similarities between them.

### Prepare data

Prepare the data for use with the `dtwclust` package, pivoting the panel data to a wide format and matrix object.

```{r}
cdengue <- tdengue %>%
  select(mun, date, cases) %>%
  mutate(mun = paste0("m_", mun)) %>%
  arrange(mun, date) %>%
  pivot_wider(names_from = mun, values_from = cases) %>%
  select(-date) %>%
  t() %>%
  tslist()
```

### SBD method

The SBD method is used to cluster the municipalities, considering a shape-bases distance (k-Shape clustering algorithm). More details on the [publicated methodology](https://doi.org/10.1145/2723372.2737793).

The clustering algorithm is applied with a varying number of $k$ partitions from 3 to 8.

```{r}
k_seq <- 3:8

tic()
clust <- tsclust(
  series = cdengue, 
  type = "partitional", 
  k = k_seq,
  distance = "sbd",
  seed = 123
)
toc()
```

### Cluster Validity Indices (CVI)

To choose the number of partitions, the Silhouette statistic is observed.

```{r}
names(clust) <- paste0("k_", k_seq)
res_cvi <- sapply(clust, cvi, type = "internal") %>% 
  t() %>%
  as_tibble(rownames = "k") %>%
  arrange(-Sil)

res_cvi %>%
  kbl() %>%
  kable_styling()
```

### Select cluster with higher Silhouette statistic

```{r}
sel_clust <- clust[[res_cvi[[1,1]]]]

plot(sel_clust)
```

### Identify municipalities and cluster id

Finally, the cluster partition ID is added to the main dataset.

```{r}
cluster_ids <- tibble(
  mun = names(cdengue) %>% substr(3, 9),
  group = as.character(sel_clust@cluster)
) 
```

```{r}
tdengue <- left_join(tdengue, cluster_ids, by = "mun")
```

## Train and test split

Split the data into training and testing. The function `time_series_split` handles the time series, not shuffling them, and considering the panel data format, as depicted in the message about overlapping timestamps detected.

```{r}
tdengue_split <- tdengue %>%
  time_series_split(
    date_var = date, 
    assess = 54*2,
    cumulative = TRUE
  )
```

## K-folds

```{r}
tdengue_split_folds <- training(tdengue_split) %>%
  vfold_cv(v = 5)
```

## Recipes

```{r}
recipes_list <- list()
```

### Global

Using data from all municipalities.

```{r}
recipe_global <- recipe(cases ~ ., data = training(tdengue_split)) %>%
  step_rm(date, group) %>%
  update_role(mun, new_role = "id variable")

recipes_list <- append(recipes_list, list(global = recipe_global))

rm(recipe_global)
```

### Groups

One recipe for each group, with data only from the group.

```{r}
for(g in unique(tdengue$group)){
  tmp <- recipe(cases ~ ., data = training(tdengue_split)) %>%
    step_filter(group == !!g) %>%
    step_rm(date, group) %>%
    update_role(mun, new_role = "id variable")
  
  tmp <- list(tmp)
  tmp <- setNames(tmp, paste0("g", g))
  
  recipes_list <- append(recipes_list, tmp)
  
  rm(tmp)
}
```

## Models specification

### Random forest

```{r}
rf_spec <- rand_forest(
  trees = tune(),
  min_n = tune()
) %>%
  set_engine("ranger") %>%
  set_mode("regression")
```

### LightGBM

```{r}
# lgbm_spec <- boost_tree() %>%
#   set_engine("lightgbm") %>%
#   set_mode("regression")
```

## Workflow set

```{r}
all_workflows <- workflow_set(
  preproc = recipes_list, 
  models = list(rf = rf_spec), 
  cross = TRUE
)
```

## Tune

```{r}
doParallel::registerDoParallel()

tic()
race_results <- 
  all_workflows %>%
  workflow_map(
    "tune_race_anova",
    seed = 345,
    resamples = tdengue_split_folds,
    grid = 10,
    control = control_race(parallel_over = "everything"),
    verbose = TRUE
  )
toc()
```

## Fit

For combination of each municipality, model and recipe.

```{r}
trained_models <- list()
for(w in unique(race_results$wflow_id)){
  best_tune <- race_results %>%
    extract_workflow_set_result(w) %>%
    select_best("rmse")
  
  final_fit <- race_results %>%
    extract_workflow(w) %>%
    finalize_workflow(best_tune) %>%
    fit(training(tdengue_split))
  
  mold <- extract_mold(final_fit)
  train_ids <- mold$extras$roles$`id variable` %>%
    distinct() %>%
    pull() %>%
    as.character()
  
  final_fit <- list(
    list(
      "final_fit" = final_fit, 
      "train_ids" = train_ids
    )
  )
  
  final_fit <- setNames(final_fit, paste0(w))
  
  trained_models <- append(trained_models, final_fit)
}
```

```{r}
models_accuracy <- tibble()
for(t in 1:length(trained_models)){
  
  model_tbl <- modeltime_table(trained_models[[t]][[1]]) 
  testing_set <- testing(tdengue_split) %>%
    filter(mun %in% trained_models[[t]][[2]])
  

  calib_tbl <- model_tbl %>%
      modeltime_calibrate(
        new_data = testing_set, 
        id       = "mun"
      )
  
  res <- calib_tbl %>% 
      modeltime_accuracy(
        acc_by_id = TRUE, 
        metric_set = metric_set(rmse)
      )
  
  res$.model_id <- word(names(trained_models[t]), 1, sep = "_")
  
  models_accuracy <- bind_rows(models_accuracy, res)
}
```

```{r}
ggplot(data = models_accuracy, aes(x = .model_id, y = rmse, fill = .model_desc)) +
  geom_boxplot()
```

## Session info

```{r}
sessionInfo()
```

## References

-   <https://blog.bguarisma.com/series/time-series-forecasting>
-   <https://business-science.github.io/modeltime/articles/modeling-panel-data.html>
