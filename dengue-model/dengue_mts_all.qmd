---
title: "Multivariate clustering, all data model"
author: "Raphael Saldanha"
date: last-modified
bibliography: references.bib
---

This notebooks aims to reproduce the methodology of the paper submitted to the SBD2023 conference, implementing the global and subset modelling with a multivariate approach.

This methodology aims to compare the performance of models trained with data from all municipalities time-series (*global models*) and models trained with subset of municipalities time-series (*subset models*).

Those subsets were created by a clustering algorithm considering the cases and climate time-series.

## Packages

```{r}
#| message: false
library(tidyverse)
library(arrow)
library(tidymodels)
library(bonsai)
library(finetune)
library(modeltime)
library(timetk)
library(dtwclust)
library(kableExtra)
library(tictoc)
library(geobr)
library(DT)
library(sf)
source("../functions.R")
```

## Load data

```{r}
tdengue <- read_parquet(file = data_dir("bundled_data/tdengue.parquet")) %>%
  select(mun, date, starts_with(c("cases", "tmax", "tmin", "prec"))) %>%
  drop_na()
```

::: callout-note
-   NA values are created when the lagged variables were calculated. The rows containing those NA values are dropped due machine learning regressors constraints.

-   Cases, maximum temperature, minimum temperature, precipitation variables are loaded, and also their time-lagged variables (from 1 to 6 weeks).
:::

```{r}
glimpse(tdengue)
```

## Clustering

Here we load the results from this [clustering notebook](../dengue-cluster/cluster_multivariate_all.qmd).

```{r}
clust_res <- readRDS("../dengue-cluster/m_cluster_ids.rds") %>%
  st_drop_geometry() %>%
  select(mun = code_muni, group)

table(clust_res$group)
```

Join clustering results with bundled dataset.

```{r}
tdengue <- left_join(tdengue, clust_res, by = "mun") %>%
  relocate(group, .after = mun)
```

Check for NAs.

```{r}
table(is.na(tdengue$group))
```

## Train and test split

Split the data into training and testing. The function `time_series_split` handles the time series, not shuffling them, and considering the panel data format, as depicted in the message about overlapping timestamps detected.

The last two years data will be used as the training set.

```{r}
tdengue_split <- tdengue %>%
  time_series_split(
    date_var = date, 
    assess = 52*2,
    cumulative = TRUE
  )

tdengue_split
```

#### K-folds

The training set will be split into k folds.

```{r}
tdengue_split_folds <- training(tdengue_split) %>%
  vfold_cv(v = 10)
```

## Recipes

The global and subset models training specification are called recipes. The procedure bellow creates a list of those recipes.

```{r}
recipes_list <- list()
```

### Global model

The global training recipe uses data from all municipalities for training the models.

-   The date and group variables are removed prior training

-   The municipality identification variable is treated as an Id variable, taking no place as a predictor in the training process

```{r}
recipe_global <- recipe(cases ~ ., data = training(tdengue_split)) %>%
  step_rm(date, group) %>%
  update_role(mun, new_role = "id variable")

recipes_list <- append(recipes_list, list(global = recipe_global))

rm(recipe_global)
```

### Global model with subset ID (one-hot-encoding)

This global model has the group variable as a predictor, in one-hot encoding form.

```{r}
recipe_globalHotID <- recipe(cases ~ ., data = training(tdengue_split)) %>%
  step_rm(date) %>%
  step_dummy(group, one_hot = TRUE) %>%
  update_role(mun, new_role = "id variable")

recipes_list <- append(recipes_list, list(globalHotID = recipe_globalHotID))

rm(recipe_globalHotID)
```

### Global model with subset ID (factor)

This global model has the group variable as a predictor, as a factor.

```{r}
recipe_globalID <- recipe(cases ~ ., data = training(tdengue_split)) %>%
  step_rm(date) %>%
  step_mutate(group = as.factor(group)) %>%
  update_role(mun, new_role = "id variable")

recipes_list <- append(recipes_list, list(globalID = recipe_globalID))

rm(recipe_globalID)
```

### Groups

-   For each group created by the clustering process, a specific training recipe will be created. For this, the first step is to filter rows from the training set, keeping only the rows belonging to the group in the loop

-   The date and group variables are removed prior to training

-   The municipality identification variable is treated as an Id variable, taking no place as a predictor in the training process

```{r}
for(g in unique(tdengue$group)){
  tmp <- recipe(cases ~ ., data = training(tdengue_split)) %>%
    step_filter(group == !!g) %>%
    step_rm(date, group) %>%
    update_role(mun, new_role = "id variable")
  
  tmp <- list(tmp)
  tmp <- setNames(tmp, paste0("g", g))
  
  recipes_list <- append(recipes_list, tmp)
  
  rm(tmp)
}
```

## Regressors specification

### Random forest

A Random Forest specification using the `ranger` engine. The `trees` and `min_n` hyperparameters will be tuned.

```{r}
rf_spec <- rand_forest(
  trees = tune(),
  min_n = tune()
) %>%
  set_engine("ranger", respect.unordered.factors = TRUE) %>%
  set_mode("regression")
```

### Workflow set

This step creates a workflow set, combining the training recipes and regressors specifications.

```{r}
all_workflows <- workflow_set(
  preproc = recipes_list, 
  models = list(rf = rf_spec), 
  cross = TRUE
)
```

## Tune

This step tunes the training hyperparameters of each workflow.

```{r}
doParallel::registerDoParallel()

tic()
race_results <- 
  all_workflows %>%
  workflow_map(
    "tune_race_anova",
    seed = 345,
    resamples = tdengue_split_folds,
    grid = 25,
    control = control_race(parallel_over = "everything"),
    verbose = TRUE
  )
toc()
```

## Fit

Each workflow will be trained using the tuned hyperparameters, considering the RMSE metric as reference.

This procedure creates a list of trained models, containing the fit results and a list of the municipalities used on the training of each workflow.

The global workflow is trained with data from all municipalities and the subsets workflows are trained using the respective municipalities list given by the cluster algorithm.

```{r}
tic()
trained_models <- list()
for(w in unique(race_results$wflow_id)){
  best_tune <- race_results %>%
    extract_workflow_set_result(w) %>%
    select_best("rmse")
  
  final_fit <- race_results %>%
    extract_workflow(w) %>%
    finalize_workflow(best_tune) %>%
    fit(training(tdengue_split))
  
  mold <- extract_mold(final_fit)
  train_ids <- mold$extras$roles$`id variable` %>%
    distinct() %>%
    pull() %>%
    as.character()
  
  final_fit <- list(
    list(
      "final_fit" = final_fit, 
      "train_ids" = train_ids
    )
  )
  
  final_fit <- setNames(final_fit, paste0(w))
  
  trained_models <- append(trained_models, final_fit)
}
toc()
```

## Accuracy

After training each workflow, the accuracy of the models are obtained applying the fitted models on the testing set.

For the global model, all municipalities are using for testing. For the subsets models, only data from the subset's municipalities are considered for testing.

The RMSE metric is obtained for each workflow and municipality.

```{r}
models_accuracy <- tibble()
for(t in 1:length(trained_models)){
  
  model_tbl <- modeltime_table(trained_models[[t]][[1]]) 
  testing_set <- testing(tdengue_split) %>%
    filter(mun %in% trained_models[[t]][[2]])
  
  calib_tbl <- model_tbl %>%
      modeltime_calibrate(
        new_data = testing_set, 
        id       = "mun"
      )
  
  res <- calib_tbl %>% 
      modeltime_accuracy(
        acc_by_id = TRUE, 
        metric_set = metric_set(rmse)
      )
  
  res$.model_id <- word(names(trained_models[t]), 1, sep = "_")
  
  models_accuracy <- bind_rows(models_accuracy, res)
}
```

```{r}
saveRDS(object = models_accuracy, file = "mts_all_accuracy.rds")
```

This plot presents the RMSE distribution across the workflows.

```{r}
ggplot(data = models_accuracy, aes(x = .model_id, y = rmse, fill = .model_id)) +
  geom_boxplot() +
  theme(legend.position = "none")
```

### Breakdown

```{r}
mun_names <- lookup_muni(code_muni = "all") %>%
  mutate(code_muni = substr(code_muni, 0, 6)) %>%
  mutate(name_muni = paste0(name_muni, ", ", abbrev_state)) %>%
  select(code_muni, name_muni)
  
models_accuracy %>% 
  left_join(mun_names, by = c("mun" = "code_muni")) %>%
  select(.model_id, .model_desc, name_muni, rmse) %>%
  mutate(rmse = round(rmse, 2)) %>%
  arrange(.model_id, .model_desc, -rmse) %>%
  datatable(filter = "top")
```

```{r}
# models_accuracy %>% 
#   left_join(mun_names, by = c("mun" = "code_muni")) %>%
#   select(.model_id, .model_desc, name_muni, rmse) %>%
#   mutate(rmse = round(rmse, 2)) %>%
#   group_by(.model_desc) %>%
#   mutate(.model_id = case_when(
#     .model_id != "global" ~ "cluster",
#     .default = .model_id
#   )) %>%
#   pivot_wider(names_from = .model_id, values_from = rmse) %>%
#   mutate(dif = round(global - cluster, 2)) %>% 
#   ungroup() %>%
#   datatable(filter = "top")
```

```{r}
# models_accuracy %>% 
#   left_join(mun_names, by = c("mun" = "code_muni")) %>%
#   select(.model_id, .model_desc, name_muni, rmse) %>%
#   group_by(.model_desc) %>%
#   mutate(.model_id = case_when(
#     .model_id != "global" ~ "cluster",
#     .default = .model_id
#   )) %>%
#   pivot_wider(names_from = .model_id, values_from = rmse) %>%
#   mutate(dif = round(global - cluster, 2)) %>% 
#   arrange(.model_desc, dif) %>%
#   ggplot(aes(x = global, y = cluster, fill = .model_desc, color = dif)) +
#   geom_point(size = 2, alpha = .3) +
#   viridis::scale_color_viridis(option = "inferno") +
#   theme_bw() +
#   labs(x = "Global model", y = "Subset models", title = "RMSE error obtained with global and subset training strategies")
```

## Session info

```{r}
sessionInfo()
```

## Useful links

-   <https://business-science.github.io/modeltime/articles/modeling-panel-data.html>

-   <https://blog.bguarisma.com/series/time-series-forecasting>
